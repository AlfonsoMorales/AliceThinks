# AliceThinks
This application is meant to serve as a demo displaying vision and machine learning frameworks to identify items. Once done the application will then translate the word(s) to a user selected language. Both words, original and translated are then spoken through the speaker.

# How It Works

Once the application is installed on the device the user simply opens the application.
<a href="https://imgflip.com/gif/2bnjhf"><img src="https://i.imgflip.com/2bnjhf.gif" title="made at imgflip.com"/></a>

In the bottom right corner of the app you will notice something called 'Recognition Process'. Here the camera view along with the Machine Learning model will give you the top results for what it believes it is looking at.
<a href="https://imgflip.com/gif/2bnjef"><img src="https://i.imgflip.com/2bnjef.gif" title="made at imgflip.com"/></a>

When you are focused on an item you may tap on the screen in the location you feel fit and an augmented 3D label will be placed in that location with the word of the top result as seen in the 'Recognition Process'
<a href="https://imgflip.com/gif/2bnjgf"><img src="https://i.imgflip.com/2bnjgf.gif" title="made at imgflip.com"/></a>
